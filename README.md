# Diff-IP2D

This is the official implementation for our paper: 

[Diff-IP2D: Diffusion-Based Hand-Object Interaction Prediction on Egocentric Videos](https://arxiv.org/abs/2405.04370).

[Junyi Ma](https://github.com/BIT-MJY), [Jingyi Xu](https://github.com/BIT-XJY), [Xieyuanli Chen](https://xieyuanli-chen.com/), [Hesheng Wang*](https://scholar.google.com/citations?hl=en&user=q6AY9XsAAAAJ&view_op=list_works&sortby=pubdate)

Diff-IP2D is the first work to jointly forecast future hand trajectories and object affordances by the devised denoising diffusion probabilistic model with only 2D egocentric videos as input. It provides a foundation generative paradigm in the field of HOI prediction.

We will release the code and relevant data upon the acceptance of our paper.
