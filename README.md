# Diff-IP2D

This is the official implementation for our paper: 

[Diff-IP2D: Diffusion-Based Hand-Object Interaction Prediction on Egocentric Videos](https://arxiv.org/abs/2405.04370).

[Junyi Ma](https://github.com/BIT-MJY), [Jingyi Xu](https://github.com/BIT-XJY), [Xieyuanli Chen](https://xieyuanli-chen.com/), [Hesheng Wang*](https://scholar.google.com/citations?hl=en&user=q6AY9XsAAAAJ&view_op=list_works&sortby=pubdate)

Diff-IP2D is the first work to jointly forecast future hand trajectories and object affordances by the devised denoising diffusion probabilistic model with only 2D egocentric videos as input. It provides a foundation generative paradigm in the field of HOI prediction.


```
@article{ma2024diffip2d,
  title={Diff-IP2D: Diffusion-Based Hand-Object Interaction Prediction on Egocentric Videos},
  author={Ma, Junyi and Xu, Jingyi and Chen, Xieyuanli and Wang, Hesheng},
  journal={arXiv preprint arXiv:2405.04370},
  year={2024}
}
```

We will release the code and relevant data upon the acceptance of our paper.
